apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: {{ .Release.Name }}-spark
spec:
  type: Scala
  mode: cluster
  image: "{{ tpl .Values.global.imageUrls.dataplaneImageUrl . }}:{{ .Values.dataplaneImage.image.dataplaneImageTag }}"
  imagePullPolicy: IfNotPresent
  imagePullSecrets:
    - regcred
  restartPolicy:
    type: Always
    onFailureRetries: 1000
    onFailureRetryInterval: 10
    onSubmissionFailureRetries: 1000
    onSubmissionFailureRetryInterval: 10
  mainClass: io.qualytics.dataplane.SparkMothership
  mainApplicationFile: "local:///opt/spark/jars/qualytics-dataplane.jar"
  sparkVersion: {{ .Values.dataplane.sparkVersion }}
  sparkConf:
    spark.eventLog.enabled: {{ .Values.dataplane.eventLog | quote }}
    spark.kubernetes.memoryOverheadFactor: {{ .Values.dataplane.memoryOverheadFactor | quote }}
    spark.kubernetes.submission.connectionTimeout: "480000"
    spark.kubernetes.submission.requestTimeout: "480000"
    spark.kubernetes.driver.connectionTimeout: "480000"
    spark.kubernetes.driver.requestTimeout: "480000"
  {{- if gt ( .Values.dataplane.numVolumes | int ) 0 }}
  volumes:
    {{- range $i := until (int .Values.dataplane.numVolumes) }}
    - name: "spark-local-dir-{{ add1 $i }}"
      {{- if ( eq $.Values.global.platform "aws" ) }}
      hostPath:
        path: "/mnt/disks/nvme{{ add1 $i }}n1/spark-local-dir-{{ add1 $i }}"
      {{- else if ( eq $.Values.global.platform "gcp" ) }}
      hostPath:
        path: "/mnt/disks/ssd{{ $i }}/spark-local-dir-{{ add1 $i }}"
      {{- else }}
      emptyDir: {}
      {{- end }}
    {{- end }}
  {{- end }}
  driver:
{{- $resources := .Values.dataplane -}}
    {{- with $resources.driver }}
    cores: {{ .cores }}
    memory: {{ .memory }}
    {{- end }}
    {{- if .Values.driverNodeSelector }}
    nodeSelector:
      {{- toYaml .Values.driverNodeSelector | nindent 6 }}
    {{- end }}
    {{- if .Values.tolerations.driverNodeTolerations }}
    tolerations:
      {{- toYaml .Values.tolerations.driverNodeTolerations | nindent 6 }}
    {{- end }}
    javaOptions:
      "-Divy.cache.dir=/tmp
       -Divy.home=/tmp
       -Dlog4j.configurationFile=file:/opt/spark/log4j2.properties
       -Dconfig.resource=prod.conf
       -Djava.library.path=/opt/spark/libs/
       -Duser.timezone=UTC
       -XX:+UseG1GC -XX:G1HeapRegionSize=32M -XX:InitiatingHeapOccupancyPercent=35"
#--------------------------------------------------------------------------------
# Environments that require a proxy (Http, Socks, etc..) for egress
#--------------------------------------------------------------------------------
# The simplest solution is to solve for this outside of Qualytics. For example, using
#   an istio egress configured for your proxy or another similar gateway device.
#
# However, if proxy-aware applications are required, the javaOptions string above can be
#  updated to hold the relevant proxy information according to the JRE v17 spec:
#    https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/net/doc-files/net-properties.html
#
#  If additionally, authentication is required for an http(s) proxy, use the following additional
#   properties not documented on the page linked above:
#  -Dhttps.proxyUser=your_username
#  -Dhttps.proxyPassword=your_password
#  -Dhttp.proxyUser=your_username
#  -Dhttp.proxyPassword=your_password
#
    env:
      - name: MOTHERSHIP_RABBIT_HOST
        value: "{{ .Release.Name }}-rabbitmq"
      {{- if eq .Values.rabbitmq.tls.enabled false }}
      - name: MOTHERSHIP_RABBIT_PORT
        value: "5672"
      - name: MOTHERSHIP_RABBIT_USE_TLS
        value: "false"
      {{- end }}
      - name: MOTHERSHIP_RABBIT_USER
        value: "user"
      - name: MOTHERSHIP_RABBIT_PASS
        valueFrom:
          secretKeyRef:
            name: qualytics-creds
            key: rabbitmq_password
    {{- if gt ( .Values.dataplane.parallelismScaleFactor | float64 ) 0.0 }}
      - name: MOTHERSHIP_PARALLELISM_SCALE_FACTOR
        value: {{ .Values.dataplane.parallelismScaleFactor | quote }}
    {{- end }}
      - name: MOTHERSHIP_MAX_PARALLEL_SYNC_REQUESTS
        value: {{ .Values.dataplane.maxParallelSyncRequests | quote }}
      - name: MOTHERSHIP_MAX_EXECUTORS
        value: {{ .Values.dataplane.dynamicAllocation.maxExecutors | int | quote }}
      - name: MOTHERSHIP_NUM_CORES_PER_EXECUTOR
        value: {{ .Values.dataplane.executor.cores | int | quote  }}
      - name: MOTHERSHIP_MAX_MEMORY_PER_EXECUTOR
        value: {{ .Values.dataplane.executor.memory | trimSuffix "m" | int | quote }}
      - name: MOTHERSHIP_LIBPOSTAL_DATA_PATH
        value: {{ .Values.dataplane.libpostalDataPath | quote  }}
    labels:
      version: {{ .Values.dataplane.sparkVersion }}
    serviceAccount: {{ .Values.sparkoperator.spark.serviceAccount.name }}
  dynamicAllocation:
    {{- with $resources.dynamicAllocation }}
    enabled: true
    initialExecutors: {{ .initialExecutors }}
    minExecutors: {{ .minExecutors }}
    maxExecutors: {{ .maxExecutors }}
    {{- end }}
  executor:
    {{- with $resources.executor }}
    instances: {{ .instances }}
    cores: {{ .cores }}
    memory: {{ .memory }}
    {{- end }}
    javaOptions:
      "-Dlog4j.configurationFile=file:/opt/spark/log4j2.properties
       -Djava.library.path=/opt/spark/libs/
       -Duser.timezone=UTC
       -XX:+UseG1GC -XX:G1HeapRegionSize=32M -XX:InitiatingHeapOccupancyPercent=35"
    labels:
      version: {{ .Values.dataplane.sparkVersion }}
    {{- if .Values.executorNodeSelector }}
    nodeSelector:
      {{- toYaml .Values.executorNodeSelector | nindent 6 }}
    {{- end }}
    {{- if .Values.tolerations.executorNodeTolerations }}
    tolerations:
      {{- toYaml .Values.tolerations.executorNodeTolerations | nindent 6 }}
    {{- end }}
    {{- if gt ( .Values.dataplane.numVolumes | int ) 0 }}
    volumeMounts:
      {{- range $i := until (int .Values.dataplane.numVolumes) }}
      - name: "spark-local-dir-{{ add1 $i }}"
        mountPath: "/tmp/spark-local-dir-{{ add1 $i }}"
      {{- end }}
    initContainers:
    - name: init-spark-local-dir
      image: "{{ tpl .Values.busybox.image.imageUrl . }}:{{ .Values.busybox.image.imageTag }}"
      imagePullPolicy: IfNotPresent
      command: ['sh', '-c', 'chmod 777 /tmp/spark-local-dir-*']
      securityContext:
        runAsUser: 0
      volumeMounts:
      {{- range $i := until (int .Values.dataplane.numVolumes) }}
      - name: "spark-local-dir-{{ add1 $i }}"
        mountPath: "/tmp/spark-local-dir-{{ add1 $i }}"
      {{- end }}
    {{- end }}
